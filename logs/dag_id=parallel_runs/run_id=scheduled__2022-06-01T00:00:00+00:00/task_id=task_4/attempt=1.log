[2022-06-02 11:42:20,365] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: parallel_runs.task_4 scheduled__2022-06-01T00:00:00+00:00 [queued]>
[2022-06-02 11:42:20,369] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: parallel_runs.task_4 scheduled__2022-06-01T00:00:00+00:00 [queued]>
[2022-06-02 11:42:20,369] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-02 11:42:20,369] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-02 11:42:20,369] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-02 11:42:20,378] {taskinstance.py:1378} INFO - Executing <Task(BashOperator): task_4> on 2022-06-01 00:00:00+00:00
[2022-06-02 11:42:20,398] {standard_task_runner.py:52} INFO - Started process 13487 to run task
[2022-06-02 11:42:20,403] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'parallel_runs', 'task_4', 'scheduled__2022-06-01T00:00:00+00:00', '--job-id', '28', '--raw', '--subdir', 'DAGS_FOLDER/parallel_runs.py', '--cfg-path', '/tmp/tmpzqd75osa', '--error-file', '/tmp/tmpollo_2h2']
[2022-06-02 11:42:20,404] {standard_task_runner.py:80} INFO - Job 28: Subtask task_4
[2022-06-02 11:42:20,436] {task_command.py:370} INFO - Running <TaskInstance: parallel_runs.task_4 scheduled__2022-06-01T00:00:00+00:00 [running]> on host TIGER0990.tigeranalytics.local
[2022-06-02 11:42:20,471] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=parallel_runs
AIRFLOW_CTX_TASK_ID=task_4
AIRFLOW_CTX_EXECUTION_DATE=2022-06-01T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-01T00:00:00+00:00
[2022-06-02 11:42:20,472] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-06-02 11:42:20,473] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'sleep 3']
[2022-06-02 11:42:20,498] {subprocess.py:85} INFO - Output:
[2022-06-02 11:42:23,508] {subprocess.py:96} INFO - Command exited with return code 0
[2022-06-02 11:42:23,528] {taskinstance.py:1890} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/smita/miniconda3/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 928, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/home/smita/miniconda3/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 669, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/smita/miniconda3/lib/python3.8/contextlib.py", line 120, in __exit__
    next(self.gen)
  File "/home/smita/miniconda3/lib/python3.8/site-packages/airflow/utils/session.py", line 33, in create_session
    session.commit()
  File "/home/smita/miniconda3/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1423, in commit
    self._transaction.commit(_to_root=self.future)
  File "/home/smita/miniconda3/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 836, in commit
    trans.commit()
  File "/home/smita/miniconda3/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2265, in commit
    self._do_commit()
  File "/home/smita/miniconda3/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2440, in _do_commit
    self._connection_commit_impl()
  File "/home/smita/miniconda3/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2411, in _connection_commit_impl
    self.connection._commit_impl()
  File "/home/smita/miniconda3/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 930, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/home/smita/miniconda3/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1929, in _handle_dbapi_exception
    util.raise_(
  File "/home/smita/miniconda3/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/smita/miniconda3/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 928, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/home/smita/miniconda3/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 669, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/14/e3q8)
[2022-06-02 11:42:23,535] {taskinstance.py:1396} INFO - Marking task as FAILED. dag_id=parallel_runs, task_id=task_4, execution_date=20220601T000000, start_date=20220602T061220, end_date=20220602T061223
[2022-06-02 11:42:23,554] {standard_task_runner.py:92} ERROR - Failed to execute job 28 for task task_4 ((sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/14/e3q8); 13487)
[2022-06-02 11:42:23,573] {local_task_job.py:156} INFO - Task exited with return code 1
[2022-06-02 11:42:23,605] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-02 11:42:23,614] {dagrun.py:547} ERROR - Marking run <DagRun parallel_runs @ 2022-06-01 00:00:00+00:00: scheduled__2022-06-01T00:00:00+00:00, externally triggered: False> failed
[2022-06-02 11:42:23,614] {dagrun.py:607} INFO - DagRun Finished: dag_id=parallel_runs, execution_date=2022-06-01 00:00:00+00:00, run_id=scheduled__2022-06-01T00:00:00+00:00, run_start_date=2022-06-02 06:12:03.347205+00:00, run_end_date=2022-06-02 06:12:23.614709+00:00, run_duration=20.267504, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2022-06-01 00:00:00+00:00, data_interval_end=2022-06-02 00:00:00+00:00, dag_hash=b60b5c1ce2c3c53f041a6a95af14dc5f
[2022-06-02 12:49:50,738] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: parallel_runs.task_4 scheduled__2022-06-01T00:00:00+00:00 [queued]>
[2022-06-02 12:49:50,748] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: parallel_runs.task_4 scheduled__2022-06-01T00:00:00+00:00 [queued]>
[2022-06-02 12:49:50,748] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-02 12:49:50,748] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-02 12:49:50,748] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-02 12:49:50,764] {taskinstance.py:1378} INFO - Executing <Task(BashOperator): task_4> on 2022-06-01 00:00:00+00:00
[2022-06-02 12:49:50,804] {standard_task_runner.py:52} INFO - Started process 21766 to run task
[2022-06-02 12:49:50,812] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'parallel_runs', 'task_4', 'scheduled__2022-06-01T00:00:00+00:00', '--job-id', '5', '--raw', '--subdir', 'DAGS_FOLDER/parallel_runs.py', '--cfg-path', '/tmp/tmprm11rihb', '--error-file', '/tmp/tmp9pv382z7']
[2022-06-02 12:49:50,815] {standard_task_runner.py:80} INFO - Job 5: Subtask task_4
[2022-06-02 12:49:51,074] {task_command.py:370} INFO - Running <TaskInstance: parallel_runs.task_4 scheduled__2022-06-01T00:00:00+00:00 [running]> on host TIGER0990.tigeranalytics.local
[2022-06-02 12:49:51,339] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=parallel_runs
AIRFLOW_CTX_TASK_ID=task_4
AIRFLOW_CTX_EXECUTION_DATE=2022-06-01T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-01T00:00:00+00:00
[2022-06-02 12:49:51,341] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-06-02 12:49:51,342] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'sleep 3']
[2022-06-02 12:49:51,391] {subprocess.py:85} INFO - Output:
[2022-06-02 12:49:54,408] {subprocess.py:96} INFO - Command exited with return code 0
[2022-06-02 12:49:54,606] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=parallel_runs, task_id=task_4, execution_date=20220601T000000, start_date=20220602T071950, end_date=20220602T071954
[2022-06-02 12:49:54,633] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-02 12:49:54,805] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
