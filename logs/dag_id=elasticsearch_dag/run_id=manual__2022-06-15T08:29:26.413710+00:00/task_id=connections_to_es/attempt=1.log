[2022-06-15 13:59:29,088] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: elasticsearch_dag.connections_to_es manual__2022-06-15T08:29:26.413710+00:00 [queued]>
[2022-06-15 13:59:29,098] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: elasticsearch_dag.connections_to_es manual__2022-06-15T08:29:26.413710+00:00 [queued]>
[2022-06-15 13:59:29,098] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-15 13:59:29,098] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-15 13:59:29,098] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-15 13:59:29,109] {taskinstance.py:1378} INFO - Executing <Task(PostgresToElasticOperator): connections_to_es> on 2022-06-15 08:29:26.413710+00:00
[2022-06-15 13:59:29,135] {standard_task_runner.py:52} INFO - Started process 7037 to run task
[2022-06-15 13:59:29,140] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'elasticsearch_dag', 'connections_to_es', 'manual__2022-06-15T08:29:26.413710+00:00', '--job-id', '110', '--raw', '--subdir', 'DAGS_FOLDER/elasticsearch_dag.py', '--cfg-path', '/tmp/tmpvzwq99lw', '--error-file', '/tmp/tmp2jbaxpi6']
[2022-06-15 13:59:29,142] {standard_task_runner.py:80} INFO - Job 110: Subtask connections_to_es
[2022-06-15 13:59:29,270] {task_command.py:370} INFO - Running <TaskInstance: elasticsearch_dag.connections_to_es manual__2022-06-15T08:29:26.413710+00:00 [running]> on host TIGER0990.tigeranalytics.local
[2022-06-15 13:59:29,386] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=elasticsearch_dag
AIRFLOW_CTX_TASK_ID=connections_to_es
AIRFLOW_CTX_EXECUTION_DATE=2022-06-15T08:29:26.413710+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=manual__2022-06-15T08:29:26.413710+00:00
[2022-06-15 13:59:29,413] {base.py:68} INFO - Using connection ID 'elasticsearch_default' for task execution.
[2022-06-15 13:59:29,440] {base.py:68} INFO - Using connection ID '***_default' for task execution.
[2022-06-15 13:59:30,394] {logging_mixin.py:115} WARNING - /home/smita/miniconda3/lib/python3.8/site-packages/elasticsearch/connection/base.py:193 ElasticsearchDeprecationWarning: Elasticsearch built-in security features are not enabled. Without authentication, your cluster could be accessible to anyone. See https://www.elastic.co/guide/en/elasticsearch/reference/7.17/security-minimal-setup.html to enable security.
[2022-06-15 13:59:30,395] {logging_mixin.py:115} WARNING - /home/smita/miniconda3/lib/python3.8/site-packages/elasticsearch/connection/base.py:193 ElasticsearchDeprecationWarning: [types removal] Specifying types in document index requests is deprecated, use the typeless endpoints instead (/{index}/_doc/{id}, /{index}/_doc, or /{index}/_create/{id}).
[2022-06-15 13:59:30,395] {base.py:278} WARNING - POST http://localhost:9200/connections/external [status:400 request:0.927s]
[2022-06-15 13:59:30,396] {taskinstance.py:1890} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/smita/airflow/plugins/elasticsearch_plugin/operators/postgres_to_elastic.py", line 30, in execute
    es.add_doc(index=self.index, doc_type='external', doc=doc)
  File "/home/smita/airflow/plugins/elasticsearch_plugin/hooks/elastic_hook.py", line 32, in add_doc
    res = self.es.index(index=index, doc_type=doc_type, body=doc)
  File "/home/smita/miniconda3/lib/python3.8/site-packages/elasticsearch/client/utils.py", line 152, in _wrapped
    return func(*args, params=params, headers=headers, **kwargs)
  File "/home/smita/miniconda3/lib/python3.8/site-packages/elasticsearch/client/__init__.py", line 398, in index
    return self.transport.perform_request(
  File "/home/smita/miniconda3/lib/python3.8/site-packages/elasticsearch/transport.py", line 392, in perform_request
    raise e
  File "/home/smita/miniconda3/lib/python3.8/site-packages/elasticsearch/transport.py", line 358, in perform_request
    status, headers_response, data = connection.perform_request(
  File "/home/smita/miniconda3/lib/python3.8/site-packages/elasticsearch/connection/http_urllib3.py", line 269, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/smita/miniconda3/lib/python3.8/site-packages/elasticsearch/connection/base.py", line 315, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(
elasticsearch.exceptions.RequestError: RequestError(400, 'mapper_parsing_exception', 'failed to parse')
[2022-06-15 13:59:30,436] {taskinstance.py:1396} INFO - Marking task as FAILED. dag_id=elasticsearch_dag, task_id=connections_to_es, execution_date=20220615T082926, start_date=20220615T082929, end_date=20220615T082930
[2022-06-15 13:59:30,450] {standard_task_runner.py:92} ERROR - Failed to execute job 110 for task connections_to_es (RequestError(400, 'mapper_parsing_exception', 'failed to parse'); 7037)
[2022-06-15 13:59:30,491] {local_task_job.py:156} INFO - Task exited with return code 1
[2022-06-15 13:59:30,556] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
