[2022-06-15 14:02:11,840] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: elasticsearch_dag.connections_to_es manual__2022-06-15T08:32:09.247508+00:00 [queued]>
[2022-06-15 14:02:11,849] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: elasticsearch_dag.connections_to_es manual__2022-06-15T08:32:09.247508+00:00 [queued]>
[2022-06-15 14:02:11,849] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-15 14:02:11,849] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-15 14:02:11,849] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-15 14:02:11,860] {taskinstance.py:1378} INFO - Executing <Task(PostgresToElasticOperator): connections_to_es> on 2022-06-15 08:32:09.247508+00:00
[2022-06-15 14:02:11,884] {standard_task_runner.py:52} INFO - Started process 9771 to run task
[2022-06-15 14:02:11,889] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'elasticsearch_dag', 'connections_to_es', 'manual__2022-06-15T08:32:09.247508+00:00', '--job-id', '112', '--raw', '--subdir', 'DAGS_FOLDER/elasticsearch_dag.py', '--cfg-path', '/tmp/tmpvkbj1ch9', '--error-file', '/tmp/tmpcg_rdk_9']
[2022-06-15 14:02:11,892] {standard_task_runner.py:80} INFO - Job 112: Subtask connections_to_es
[2022-06-15 14:02:12,005] {task_command.py:370} INFO - Running <TaskInstance: elasticsearch_dag.connections_to_es manual__2022-06-15T08:32:09.247508+00:00 [running]> on host TIGER0990.tigeranalytics.local
[2022-06-15 14:02:12,145] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=elasticsearch_dag
AIRFLOW_CTX_TASK_ID=connections_to_es
AIRFLOW_CTX_EXECUTION_DATE=2022-06-15T08:32:09.247508+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=manual__2022-06-15T08:32:09.247508+00:00
[2022-06-15 14:02:12,180] {base.py:68} INFO - Using connection ID 'elasticsearch_default' for task execution.
[2022-06-15 14:02:12,212] {base.py:68} INFO - Using connection ID '***_default' for task execution.
[2022-06-15 14:02:12,260] {logging_mixin.py:115} WARNING - /home/smita/miniconda3/lib/python3.8/site-packages/elasticsearch/connection/base.py:193 ElasticsearchDeprecationWarning: Elasticsearch built-in security features are not enabled. Without authentication, your cluster could be accessible to anyone. See https://www.elastic.co/guide/en/elasticsearch/reference/7.17/security-minimal-setup.html to enable security.
[2022-06-15 14:02:12,261] {logging_mixin.py:115} WARNING - /home/smita/miniconda3/lib/python3.8/site-packages/elasticsearch/connection/base.py:193 ElasticsearchDeprecationWarning: [types removal] Specifying types in document index requests is deprecated, use the typeless endpoints instead (/{index}/_doc/{id}, /{index}/_doc, or /{index}/_create/{id}).
[2022-06-15 14:02:12,262] {base.py:278} WARNING - POST http://localhost:9200/connections/external [status:400 request:0.012s]
[2022-06-15 14:02:12,262] {taskinstance.py:1890} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/smita/airflow/plugins/elasticsearch_plugin/operators/postgres_to_elastic.py", line 30, in execute
    es.add_doc(index=self.index, doc_type='external', doc=doc)
  File "/home/smita/airflow/plugins/elasticsearch_plugin/hooks/elastic_hook.py", line 32, in add_doc
    res = self.es.index(index=index, doc_type=doc_type, body=doc)
  File "/home/smita/miniconda3/lib/python3.8/site-packages/elasticsearch/client/utils.py", line 152, in _wrapped
    return func(*args, params=params, headers=headers, **kwargs)
  File "/home/smita/miniconda3/lib/python3.8/site-packages/elasticsearch/client/__init__.py", line 398, in index
    return self.transport.perform_request(
  File "/home/smita/miniconda3/lib/python3.8/site-packages/elasticsearch/transport.py", line 392, in perform_request
    raise e
  File "/home/smita/miniconda3/lib/python3.8/site-packages/elasticsearch/transport.py", line 358, in perform_request
    status, headers_response, data = connection.perform_request(
  File "/home/smita/miniconda3/lib/python3.8/site-packages/elasticsearch/connection/http_urllib3.py", line 269, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/smita/miniconda3/lib/python3.8/site-packages/elasticsearch/connection/base.py", line 315, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(
elasticsearch.exceptions.RequestError: RequestError(400, 'mapper_parsing_exception', 'failed to parse')
[2022-06-15 14:02:12,291] {taskinstance.py:1396} INFO - Marking task as FAILED. dag_id=elasticsearch_dag, task_id=connections_to_es, execution_date=20220615T083209, start_date=20220615T083211, end_date=20220615T083212
[2022-06-15 14:02:12,303] {standard_task_runner.py:92} ERROR - Failed to execute job 112 for task connections_to_es (RequestError(400, 'mapper_parsing_exception', 'failed to parse'); 9771)
[2022-06-15 14:02:12,309] {local_task_job.py:156} INFO - Task exited with return code 1
[2022-06-15 14:02:12,378] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
